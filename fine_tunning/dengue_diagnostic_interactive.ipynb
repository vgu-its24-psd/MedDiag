{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/long-nguyen-bao-ts/test/blob/main/dengue_diagnostic_interactive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HQs8v7G14Z6"
      },
      "source": [
        "# Interactive Dengue Fever Diagnostic System\n",
        "\n",
        "## Features:\n",
        "- Clinical text-based diagnosis from symptoms and lab values\n",
        "- Medical image-based diagnosis\n",
        "- Combined multimodal diagnosis (text + image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcjwIJjg14Z7"
      },
      "source": [
        "## Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dl_nSAF714Z8"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install --upgrade --quiet transformers torch pillow gradio peft accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVpHgsDM14Z8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "import os\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE50B2tF14Z8"
      },
      "source": [
        "## Load Fine-tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tIVQAyF14Z8"
      },
      "outputs": [],
      "source": [
        "class DengueDiagnosticSystem:\n",
        "    def __init__(self, model_id=\"longbao128/gemma-4b-dengue-diagnosis\"):\n",
        "        self.model_id = model_id\n",
        "        self.processor = None\n",
        "        self.model = None\n",
        "        self.model_loaded = False\n",
        "        logger.info(f\"Initializing Dengue Diagnostic System with model: {model_id}\")\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load the fine-tuned model and processor\"\"\"\n",
        "        if self.model_loaded:\n",
        "            return True\n",
        "\n",
        "        try:\n",
        "            logger.info(\"Loading processor...\")\n",
        "            self.processor = AutoProcessor.from_pretrained(self.model_id)\n",
        "\n",
        "            logger.info(\"Loading model... This may take a few minutes.\")\n",
        "            self.model = AutoModelForImageTextToText.from_pretrained(\n",
        "                self.model_id,\n",
        "                torch_dtype=torch.bfloat16,\n",
        "                device_map=\"auto\"\n",
        "            )\n",
        "\n",
        "            # Configure for inference\n",
        "            self.model.generation_config.do_sample = False\n",
        "            self.model.generation_config.pad_token_id = self.processor.tokenizer.eos_token_id\n",
        "            self.processor.tokenizer.padding_side = \"left\"\n",
        "\n",
        "            self.model_loaded = True\n",
        "            logger.info(\"✅ Model loaded successfully!\")\n",
        "            logger.info(f\"✅ Running on device: {self.model.device}\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to load model: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def is_dengue_related(self, clinical_info: str) -> tuple:\n",
        "        \"\"\"Check if input is related to dengue fever diagnosis\"\"\"\n",
        "        info_lower = clinical_info.lower()\n",
        "\n",
        "        # Dengue-related keywords\n",
        "        dengue_keywords = ['dengue', 'fever', 'temperature', 'platelet', 'wbc', 'headache',\n",
        "                          'pain behind eyes', 'joint', 'muscle aches', 'rash', 'hemorrhage',\n",
        "                          'thrombocytopenia', 'hemoglobin', 'hematocrit', 'nausea', 'vomiting',\n",
        "                          'abdominal pain', 'patient', 'lab values', 'symptoms', 'diagnosis']\n",
        "\n",
        "        # Non-medical/random keywords that indicate irrelevant input\n",
        "        irrelevant_keywords = ['hello', 'hi', 'test', 'random', 'asdf', 'qwerty', '123',\n",
        "                              'weather', 'football', 'car', 'computer', 'programming',\n",
        "                              'movie', 'game', 'music', 'food', 'restaurant']\n",
        "\n",
        "        # Check for irrelevant content\n",
        "        has_irrelevant = any(keyword in info_lower for keyword in irrelevant_keywords)\n",
        "        has_medical = any(keyword in info_lower for keyword in dengue_keywords[:5])\n",
        "\n",
        "        if has_irrelevant and not has_medical:\n",
        "            return False, \"\"\"⚠️ **NOT RELATED TO DENGUE DIAGNOSIS**\n",
        "\n",
        "The input appears to be unrelated to medical diagnosis or dengue fever.\n",
        "\n",
        "**This system is specifically designed for dengue fever diagnosis.**\n",
        "\n",
        "Please provide:\n",
        "- Patient symptoms (fever, headache, pain behind eyes, joint/muscle aches, rash, etc.)\n",
        "- Laboratory values (WBC, platelet count, hemoglobin, hematocrit, etc.)\n",
        "- Clinical history and fever duration\n",
        "- Patient demographics\n",
        "\n",
        "If you need general medical assistance, please consult a healthcare professional.\"\"\"\n",
        "\n",
        "        # Check for minimum medical context\n",
        "        if len(info_lower.split()) < 10:\n",
        "            return False, \"\"\"⚠️ **INSUFFICIENT INFORMATION**\n",
        "\n",
        "Please provide more detailed clinical information for diagnosis, including:\n",
        "- Patient symptoms and their duration\n",
        "- Laboratory test results\n",
        "- Fever status and temperature\n",
        "- Other relevant clinical details\n",
        "\n",
        "Example format:\n",
        "\"Patient from [location], fever duration: X days, current temperature: XXX°F\n",
        "Lab values - WBC: X, Platelet: X\n",
        "Present symptoms: [list]\n",
        "Absent symptoms: [list]\" \"\"\"\n",
        "\n",
        "        # Check if it contains at least some medical context\n",
        "        medical_word_count = sum(1 for keyword in dengue_keywords if keyword in info_lower)\n",
        "        if medical_word_count < 2:\n",
        "            return False, \"\"\"⚠️ **CANNOT PROCESS - NOT RELATED TO SYSTEM**\n",
        "\n",
        "This system is specifically designed for dengue fever diagnosis. The provided information does not appear to contain relevant medical or clinical data.\n",
        "\n",
        "**For dengue diagnosis, please provide:**\n",
        "- Fever status and duration\n",
        "- Clinical symptoms (headache, pain behind eyes, joint/muscle aches, rash, etc.)\n",
        "- Laboratory results (platelet count, WBC, hemoglobin, etc.)\n",
        "- Patient demographics and history\n",
        "\n",
        "**This system cannot process:**\n",
        "- General questions\n",
        "- Non-medical inquiries\n",
        "- Random text or test inputs\"\"\"\n",
        "\n",
        "        return True, \"\"\n",
        "\n",
        "    def create_clinical_prompt(self, clinical_info: str) -> str:\n",
        "        \"\"\"Create formatted prompt for clinical text diagnosis (matches training format)\"\"\"\n",
        "        prompt = f\"\"\"You are a medical AI assistant specializing in dengue fever diagnosis. Analyze the following clinical case and provide a diagnosis with detailed explanation.\n",
        "\n",
        "Clinical Information:\n",
        "{clinical_info}\n",
        "\n",
        "Instructions:\n",
        "- Consider both present and absent symptoms in your diagnosis\n",
        "- When symptom information is unknown, factor this uncertainty into your assessment\n",
        "- Base your diagnosis on available clinical evidence\n",
        "- Dengue fever typically presents with fever, headache, pain behind eyes, joint/muscle aches, and low platelet count\n",
        "\n",
        "Question: Based on the available clinical data, does this patient have dengue fever?\n",
        "\n",
        "Provide your diagnosis as either \"Yes - Dengue positive\" or \"No - Dengue negative\".\n",
        "Then provide a brief explanation (1-2 sentences) of the key factors supporting your diagnosis, mentioning specific symptoms or lab values that influenced your decision.\"\"\"\n",
        "        return prompt\n",
        "\n",
        "    def create_image_prompt(self) -> str:\n",
        "        \"\"\"Create formatted prompt for medical image diagnosis (matches training format)\"\"\"\n",
        "        prompt = \"\"\"You are a medical AI assistant analyzing medical imagery for signs of dengue fever.\n",
        "\n",
        "Analyze this medical image carefully for visual evidence of dengue fever symptoms or complications.\n",
        "\n",
        "Instructions:\n",
        "- Look for skin manifestations (rash, petechiae)\n",
        "- Consider any visible clinical signs\n",
        "- Provide your assessment based on the visual evidence\n",
        "\n",
        "Question: Based on the visual evidence in this medical image, does this show signs consistent with dengue fever?\n",
        "\n",
        "Respond with \"Yes - Dengue positive\" or \"No - Dengue negative\".\n",
        "Then briefly explain (1 sentence) what visual features you observed that support your diagnosis.\"\"\"\n",
        "        return prompt\n",
        "\n",
        "    def parse_diagnosis(self, response_text: str) -> tuple:\n",
        "        \"\"\"Parse model response to extract diagnosis\"\"\"\n",
        "        response_lower = response_text.lower()\n",
        "\n",
        "        # Check for exact trained responses\n",
        "        if \"yes - dengue positive\" in response_lower or \"yes-dengue positive\" in response_lower:\n",
        "            return \"🔴 DENGUE POSITIVE\", \"positive\", response_text\n",
        "        elif \"no - dengue negative\" in response_lower or \"no-dengue negative\" in response_lower:\n",
        "            return \"🟢 DENGUE NEGATIVE\", \"negative\", response_text\n",
        "        else:\n",
        "            # Fallback for partial matches\n",
        "            if (\"positive\" in response_lower and \"dengue\" in response_lower) or \\\n",
        "               (\"yes\" in response_lower and \"dengue\" in response_lower):\n",
        "                return \"🔴 DENGUE POSITIVE (uncertain)\", \"positive\", response_text\n",
        "            elif (\"negative\" in response_lower and \"dengue\" in response_lower) or \\\n",
        "                 (\"no\" in response_lower and \"dengue\" in response_lower):\n",
        "                return \"🟢 DENGUE NEGATIVE (uncertain)\", \"negative\", response_text\n",
        "            else:\n",
        "                return \"⚠️ UNCERTAIN DIAGNOSIS\", \"uncertain\", response_text\n",
        "\n",
        "    def diagnose_text(self, clinical_info: str) -> str:\n",
        "        \"\"\"Diagnose dengue from clinical text information\"\"\"\n",
        "        if not clinical_info or clinical_info.strip() == \"\":\n",
        "            return \"⚠️ **Error**: Please provide clinical information for diagnosis.\"\n",
        "\n",
        "        # Validate input is dengue-related\n",
        "        is_valid, error_message = self.is_dengue_related(clinical_info)\n",
        "        if not is_valid:\n",
        "            return error_message\n",
        "\n",
        "        if not self.model_loaded:\n",
        "            if not self.load_model():\n",
        "                return \"❌ **Error**: Failed to load model. Please check logs.\"\n",
        "\n",
        "        try:\n",
        "            logger.info(\"Processing clinical text diagnosis...\")\n",
        "            prompt = self.create_clinical_prompt(clinical_info)\n",
        "\n",
        "            # Format exactly as in training\n",
        "            messages = [\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"text\", \"text\": prompt}\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "\n",
        "            # Apply chat template with generation prompt\n",
        "            text = self.processor.apply_chat_template(\n",
        "                messages,\n",
        "                add_generation_prompt=True,\n",
        "                tokenize=False\n",
        "            ).strip()\n",
        "\n",
        "            # Tokenize and generate (increased max tokens for explanation)\n",
        "            inputs = self.processor(text=text, return_tensors=\"pt\", padding=True)\n",
        "            inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
        "\n",
        "            logger.info(\"Generating diagnosis...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(\n",
        "                    **inputs,\n",
        "                    max_new_tokens=150,  # Increased for explanation\n",
        "                    pad_token_id=self.processor.tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "            # Decode full response\n",
        "            full_response = self.processor.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "            # Extract only the assistant's response (after the last \"model\" marker)\n",
        "            if \"model\" in full_response:\n",
        "                parts = full_response.split(\"model\")\n",
        "                response = parts[-1].strip()\n",
        "            else:\n",
        "                response = full_response\n",
        "\n",
        "            logger.info(f\"Raw model response: {response}\")\n",
        "\n",
        "            # Parse diagnosis\n",
        "            diagnosis, category, full_text = self.parse_diagnosis(response)\n",
        "\n",
        "            # Format output with explanation\n",
        "            result = f\"### {diagnosis}\\n\\n\"\n",
        "            result += f\"**AI Diagnostic Response:**\\n{full_text}\\n\\n\"\n",
        "            result += f\"**Clinical Information Provided:**\\n{clinical_info[:300]}{'...' if len(clinical_info) > 300 else ''}\"\n",
        "\n",
        "            logger.info(f\"Diagnosis completed: {category}\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during diagnosis: {str(e)}\")\n",
        "            return f\"❌ **Error during diagnosis:** {str(e)}\"\n",
        "\n",
        "    def diagnose_image(self, image_path: str) -> str:\n",
        "        \"\"\"Diagnose dengue from medical image\"\"\"\n",
        "        if not image_path or image_path.strip() == \"\":\n",
        "            return \"⚠️ **Error**: Please provide an image path for diagnosis.\"\n",
        "\n",
        "        if not self.model_loaded:\n",
        "            if not self.load_model():\n",
        "                return \"❌ **Error**: Failed to load model. Please check logs.\"\n",
        "\n",
        "        try:\n",
        "            # Validate image path\n",
        "            if not os.path.exists(image_path):\n",
        "                return f\"❌ **Error**: Image file not found at: {image_path}\"\n",
        "\n",
        "            logger.info(f\"Loading image from: {image_path}\")\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "            prompt = self.create_image_prompt()\n",
        "\n",
        "            # Format exactly as in training\n",
        "            messages = [\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"image\"},\n",
        "                        {\"type\": \"text\", \"text\": prompt}\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "\n",
        "            # Apply chat template with generation prompt\n",
        "            text = self.processor.apply_chat_template(\n",
        "                messages,\n",
        "                add_generation_prompt=True,\n",
        "                tokenize=False\n",
        "            ).strip()\n",
        "\n",
        "            # Process with image\n",
        "            inputs = self.processor(text=text, images=[image], return_tensors=\"pt\", padding=True)\n",
        "            inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
        "\n",
        "            logger.info(\"Generating image-based diagnosis...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(\n",
        "                    **inputs,\n",
        "                    max_new_tokens=100,  # Increased for explanation\n",
        "                    pad_token_id=self.processor.tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "            # Decode full response\n",
        "            full_response = self.processor.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "            # Extract only the assistant's response\n",
        "            if \"model\" in full_response:\n",
        "                parts = full_response.split(\"model\")\n",
        "                response = parts[-1].strip()\n",
        "            else:\n",
        "                response = full_response\n",
        "\n",
        "            logger.info(f\"Raw model response: {response}\")\n",
        "\n",
        "            # Parse diagnosis\n",
        "            diagnosis, category, full_text = self.parse_diagnosis(response)\n",
        "\n",
        "            # Format output\n",
        "            result = f\"### {diagnosis}\\n\\n\"\n",
        "            result += f\"**AI Diagnostic Response:**\\n{full_text}\\n\\n\"\n",
        "            result += f\"**Image Analyzed:** {image_path}\"\n",
        "\n",
        "            logger.info(f\"Diagnosis completed: {category}\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during image diagnosis: {str(e)}\")\n",
        "            return f\"❌ **Error during diagnosis:** {str(e)}\"\n",
        "\n",
        "    def diagnose_multimodal(self, clinical_info: str, image_path: str) -> str:\n",
        "        \"\"\"Diagnose dengue using both clinical text and medical image\"\"\"\n",
        "        has_text = clinical_info and clinical_info.strip() != \"\"\n",
        "        has_image = image_path and image_path.strip() != \"\"\n",
        "\n",
        "        if not has_text and not has_image:\n",
        "            return \"⚠️ **Error**: Please provide either clinical information or an image (or both) for diagnosis.\"\n",
        "\n",
        "        results = [\"# 🩺 Dengue Fever Diagnosis Results\\n\\n\"]\n",
        "\n",
        "        # Clinical text diagnosis\n",
        "        if has_text:\n",
        "            results.append(\"## 📋 Clinical Data Analysis\\n\\n\")\n",
        "            text_result = self.diagnose_text(clinical_info)\n",
        "            results.append(text_result)\n",
        "            results.append(\"\\n\\n---\\n\\n\")\n",
        "\n",
        "        # Image diagnosis\n",
        "        if has_image:\n",
        "            results.append(\"## 🖼️ Medical Image Analysis\\n\\n\")\n",
        "            image_result = self.diagnose_image(image_path)\n",
        "            results.append(image_result)\n",
        "\n",
        "        return \"\".join(results)\n",
        "\n",
        "# Initialize the diagnostic system\n",
        "diagnostic_system = DengueDiagnosticSystem()\n",
        "print(\"✓ Diagnostic system initialized!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuccPGbk14Z-"
      },
      "source": [
        "## Launch Gradio Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTKB8yU014Z-"
      },
      "outputs": [],
      "source": [
        "# Create Gradio interface\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"Dengue Fever Diagnostic System\") as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # 🩺 Dengue Fever Diagnostic System\n",
        "\n",
        "        ---\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### 📝 Input Clinical Information\")\n",
        "\n",
        "            clinical_input = gr.Textbox(\n",
        "                label=\"Clinical Information\",\n",
        "                placeholder=\"\"\"Enter patient symptoms, lab values, and clinical history...\n",
        "\n",
        "Example format:\n",
        "Patient from Bangalore, fever duration: 10 days, current temperature: 100.0°F\n",
        "Lab values - WBC: 5.0, Platelet: 140.0\n",
        "Present symptoms: severe headache, metallic taste, appetite loss\n",
        "Absent symptoms: pain behind eyes, joint/muscle aches\"\"\",\n",
        "                lines=10\n",
        "            )\n",
        "\n",
        "            image_input = gr.Textbox(\n",
        "                label=\"Medical Image Path (optional)\",\n",
        "                placeholder=\"/path/to/medical/image.png or leave empty\",\n",
        "                lines=1\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                clear_btn = gr.Button(\"🗑️ Clear\", variant=\"secondary\")\n",
        "                diagnose_btn = gr.Button(\"🔍 Diagnose\", variant=\"primary\", scale=2)\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### 📊 Diagnosis Result\")\n",
        "            output = gr.Markdown(label=\"Result\")\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    ---\n",
        "    ### 📋 Example Cases (Click to load)\n",
        "    \"\"\")\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [\n",
        "                \"\"\"Patient from New Delhi, fever duration: 4 days, current temperature: 104.0°F.\n",
        "Lab values - WBC: 1.0, Hemoglobin: 9.0, Hematocrit: 22.0, Platelet: 80.0.\n",
        "Present symptoms: pain behind eyes, joint/muscle aches.\n",
        "Absent symptoms: severe headache, metallic taste, appetite loss, abdominal pain, nausea/vomiting, diarrhea.\n",
        "Clinical notes: Low WBC and platelet count concerning for dengue.\"\"\",\n",
        "                \"\"\n",
        "            ],\n",
        "            [\n",
        "                \"\"\"Patient from Bangalore, fever duration: 10 days, current temperature: 100.0°F.\n",
        "Lab values - WBC: 5.0, Hemoglobin: 15.0, Platelet: 140.0.\n",
        "Present symptoms: severe headache, metallic taste, appetite loss, abdominal pain, diarrhea.\n",
        "Absent symptoms: pain behind eyes, joint/muscle aches, nausea/vomiting.\n",
        "Clinical notes: Normal platelet count, symptoms not specific to dengue.\"\"\",\n",
        "                \"\"\n",
        "            ],\n",
        "            [\n",
        "                \"\"\"Patient from Jamaica, fever duration: 5 days, current temperature: 104.0°F.\n",
        "Lab values - WBC: 5.0, Platelet: 120.0.\n",
        "Present symptoms: metallic taste, appetite loss, abdominal pain, nausea/vomiting.\n",
        "Absent symptoms: pain behind eyes, joint/muscle aches.\n",
        "Symptom status unknown for: severe headache, diarrhea.\"\"\",\n",
        "                \"\"\n",
        "            ],\n",
        "            [\n",
        "                \"\"\"Patient from Miami, no fever reported, normal temperature.\n",
        "Lab values - WBC: 7.0, Platelet: 200.0.\n",
        "Present symptoms: mild cough, runny nose.\n",
        "Absent symptoms: fever, headache, pain behind eyes, joint/muscle aches, rash.\n",
        "Clinical notes: Symptoms more consistent with common cold.\"\"\",\n",
        "                \"\"\n",
        "            ]\n",
        "        ],\n",
        "        inputs=[clinical_input, image_input],\n",
        "        label=\"Click an example to load it\"\n",
        "    )\n",
        "\n",
        "\n",
        "    # Event handlers\n",
        "    def clear_inputs():\n",
        "        return \"\", \"\", \"\"\n",
        "\n",
        "    diagnose_btn.click(\n",
        "        fn=diagnostic_system.diagnose_multimodal,\n",
        "        inputs=[clinical_input, image_input],\n",
        "        outputs=output\n",
        "    )\n",
        "\n",
        "    clear_btn.click(\n",
        "        fn=clear_inputs,\n",
        "        inputs=[],\n",
        "        outputs=[clinical_input, image_input, output]\n",
        "    )\n",
        "\n",
        "# Launch interface\n",
        "print(\"\\n🚀 Launching Gradio interface...\")\n",
        "demo.launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
